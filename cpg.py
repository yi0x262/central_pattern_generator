#!/usr/env/bin python3
import numpy as np
from scipy.integrate import odeint

#Sustained Oscillations Generated by Mutually Inhibiting Neurons with Adaptation,Matsuoka,1985
#Enhancing Humanoid Learning Abilties; Scalable Learning through Task-Relevant Features (Matsubara,2007)

class cpg(object):
    def __init__(self,num,A,b=2.5,T=12,x0=[0,0,0,0,0,0]):
        """
        A (const) : strengths of an inhibitory connection between neurons (i!=j:aij>0,i==j:aij=0)
        b (const) : time cources of adaptation (2.5)
        T (const) : time cources of adaptation (12)
        """
        self.A = np.array(A)
        self.g = np.tanh

        self.b = b
        self.T = T
        self.x = np.array(x0)
        self.num = num

    #def g(self,x):
    #    return np.maximum(0,x)

    def __call__(self,t,s):
        """s:input vector"""
        self.x   = odeint(self.func,self.x,t,args=(s,))
        return self.x

    def func(self,vector,t,s):
        """
        x[0]: voltage
        x[1]: adaptation
        x[2]: output
        t   :
        s   : input
        b,T : time cources of adaptation (scalar?)

        dx/dt   = -x - yA + s - bx'
        dx'/dt  = (-x' + y)/T
        y       = g(x)
        """
        x = np.hsplit(vector,3)
        ss = np.array(s)
        return np.r_[(-x[0]-np.dot(x[2],self.A)+ss-self.b*x[1]),(-x[1]+x[2])/self.T,self.g(x[0])]

if __name__ == '__main__':
    from save_plot import logger

    neuronum = 4
    a = 2.5
    A = a - a*np.eye(neuronum)
    print(A)
    c = cpg(neuronum,A,x0=[i for i in range(neuronum)]+[i for i in range(neuronum)]+[i for i in range(neuronum)])

    s = np.ones(neuronum)*0.1
    t = np.linspace(0,50,100001)
    y = c(t,s)
    #y = [d[2*neuronum:] for d in y]
    lgr = logger(['voltage','adaptation','output'])
    for i,d in enumerate(y):
        #print(i)
        lgr.append(np.hsplit(d,3))

    lgr.output('/home/yihome/Pictures/log/cpg/',t,show=True,
        title='$A=a-aE$,a={},s={},b=2.5,T=12,g=tanh'.format(a,s))
